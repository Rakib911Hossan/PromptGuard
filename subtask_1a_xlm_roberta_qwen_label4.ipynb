{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakib911Hossan/hate_speech_detection/blob/main/subtask_1a_xlm_roberta_qwen_label4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZjOpQLseZDq",
        "outputId": "e5c2ac2e-a7dc-40bb-ef6e-b12bae9cef6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.8.3)\n",
            "--2025-09-01 04:17:52--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8002036 (7.6M) [text/plain]\n",
            "Saving to: ‘blp25_hatespeech_subtask_1A_train.tsv’\n",
            "\n",
            "blp25_hatespeech_su 100%[===================>]   7.63M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-09-01 04:17:52 (81.0 MB/s) - ‘blp25_hatespeech_subtask_1A_train.tsv’ saved [8002036/8002036]\n",
            "\n",
            "--2025-09-01 04:17:52--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 585339 (572K) [text/plain]\n",
            "Saving to: ‘blp25_hatespeech_subtask_1A_dev.tsv’\n",
            "\n",
            "blp25_hatespeech_su 100%[===================>] 571.62K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-01 04:17:52 (10.8 MB/s) - ‘blp25_hatespeech_subtask_1A_dev.tsv’ saved [585339/585339]\n",
            "\n",
            "--2025-09-01 04:17:52--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev_test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548258 (535K) [text/plain]\n",
            "Saving to: ‘blp25_hatespeech_subtask_1A_dev_test.tsv’\n",
            "\n",
            "blp25_hatespeech_su 100%[===================>] 535.41K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-01 04:17:53 (11.0 MB/s) - ‘blp25_hatespeech_subtask_1A_dev_test.tsv’ saved [548258/548258]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# HATE SPEECH CLASSIFICATION WITH XLM-ROBERTA AND QWEN AUTO-LABELING\n",
        "# Complete Google Colab Notebook\n",
        "# =============================================================================\n",
        "\n",
        "# Cell 1: Install Dependencies\n",
        "# =============================================================================\n",
        "!pip install transformers datasets scikit-learn torch openai accelerate evaluate\n",
        "!pip install --upgrade huggingface_hub\n",
        "\n",
        "# Cell 2: Download Dataset\n",
        "# =============================================================================\n",
        "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_train.tsv\n",
        "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev.tsv\n",
        "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev_test.tsv\n",
        "\n",
        "# Cell 2: Import Libraries and Setup\n",
        "# =============================================================================\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, List, Dict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed,\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import evaluate\n",
        "from openai import OpenAI\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDNQf3jqerhR",
        "outputId": "c7db01a7-2493-4cf3-c0a7-6e3e3a8c99b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {'None': 0, 'Religious Hate': 1, 'Sexism': 2, 'Political Hate': 3, 'Profane': 4, 'Abusive': 5}\n",
            "Using model: xlm-roberta-base\n",
            "Optimized configuration loaded with early stopping and regularization\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Define Label Mapping and Optimized Configuration\n",
        "# =============================================================================\n",
        "# Label to ID mapping\n",
        "l2id = {\n",
        "    \"None\": 0,\n",
        "    \"Religious Hate\": 1,\n",
        "    \"Sexism\": 2,\n",
        "    \"Political Hate\": 3,\n",
        "    \"Profane\": 4,\n",
        "    \"Abusive\": 5\n",
        "}\n",
        "\n",
        "id2l = {v: k for k, v in l2id.items()}\n",
        "\n",
        "# 🎯 OPTIMIZED CONFIGURATION BASED ON SUCCESSFUL RESULTS\n",
        "MODEL_NAME = \"xlm-roberta-base\"\n",
        "MAX_LENGTH = 512\n",
        "BATCH_SIZE = 8                           # Optimized batch size\n",
        "LEARNING_RATE = 10e-6                    # Lower LR for more stable convergence\n",
        "NUM_EPOCHS = 8                           # More epochs with early stopping\n",
        "WARMUP_RATIO = 0.15                      # Longer warmup for stability\n",
        "WEIGHT_DECAY = 0.01                      # Stronger regularization\n",
        "MAX_GRAD_NORM = 0.5                      # Tighter gradient clipping\n",
        "\n",
        "# 🎯 OPTIMIZED DATA PARAMETERS\n",
        "max_train_samples = None\n",
        "max_eval_samples = None\n",
        "max_predict_samples = None\n",
        "max_seq_length = 512\n",
        "batch_size = 8\n",
        "\n",
        "print(f\"Label mapping: {l2id}\")\n",
        "print(f\"Using model: {MODEL_NAME}\")\n",
        "print(f\"Optimized configuration loaded with early stopping and regularization\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KngXr_sYTcbH",
        "outputId": "dfc053c8-180b-46ef-d79f-691df8b1fae2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Clear PyTorch GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Run garbage collection\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BsmyuQkPu9wW"
      },
      "outputs": [],
      "source": [
        "# # Cell 5: Setup Qwen Hugging Face Model for Auto-labeling\n",
        "# # =============================================================================\n",
        "\n",
        "\n",
        "# !pip install huggingface_hub -q\n",
        "\n",
        "# from huggingface_hub import login\n",
        "\n",
        "# # Paste your HF token here (get it from https://huggingface.co/settings/tokens)\n",
        "# login(token=\"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\")\n",
        "\n",
        "\n",
        "# !pip install transformers accelerate bitsandbytes -q\n",
        "\n",
        "# import torch\n",
        "# import time\n",
        "# import pandas as pd\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# # Choose a smaller model if GPU is limited (Colab T4 works better with 0.5B or 1.8B)\n",
        "# MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "\n",
        "# # Load tokenizer & model with memory-efficient options\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     device_map=\"auto\",\n",
        "#     torch_dtype=torch.float16\n",
        "# )\n",
        "\n",
        "# # Setup pipeline for generation\n",
        "# qwen_pipeline = pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "# )\n",
        "\n",
        "# # Label mapping dictionary\n",
        "# l2id = {\n",
        "#     \"None\": 0,\n",
        "#     \"Religious Hate\": 1,\n",
        "#     \"Sexism\": 2,\n",
        "#     \"Political Hate\": 3,\n",
        "#     \"Profane\": 4,\n",
        "#     \"Abusive\": 5\n",
        "# }\n",
        "\n",
        "# def classify_text_with_qwen(text: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Classify a single text using Qwen from Hugging Face with strict multi-class prompt\n",
        "#     \"\"\"\n",
        "#     prompt = f\"\"\"You are a hate speech classification expert.\n",
        "# Classify the following text into exactly one of these categories:\n",
        "\n",
        "# None, Religious Hate, Sexism, Political Hate, Profane, Abusive\n",
        "\n",
        "# Text: \"{text}\"\n",
        "\n",
        "# Important: Respond with ONLY one category name from the list above.\"\"\"\n",
        "\n",
        "#     try:\n",
        "#         output = qwen_pipeline(\n",
        "#             prompt,\n",
        "#             max_new_tokens=10,\n",
        "#             temperature=0.0,\n",
        "#             do_sample=False\n",
        "#         )[0][\"generated_text\"]\n",
        "\n",
        "#         # Extract the last valid label\n",
        "#         for label in l2id.keys():\n",
        "#             if label in output:\n",
        "#                 return label\n",
        "\n",
        "#         print(f\"⚠️ Invalid prediction '{output}' for text: {text[:50]}...\")\n",
        "#         return \"None\"  # fallback\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error classifying text: {e}\")\n",
        "#         return \"None\"\n",
        "\n",
        "# def auto_label_missing_data(df: pd.DataFrame, batch_size: int = 16) -> pd.DataFrame:\n",
        "#     \"\"\"\n",
        "#     Auto-label missing data using Hugging Face Qwen with efficient batching.\n",
        "#     \"\"\"\n",
        "#     print(\"Starting auto-labeling with Hugging Face Qwen...\")\n",
        "#     df_copy = df.copy()\n",
        "#     missing_mask = df_copy['label'].isna()\n",
        "#     missing_count = missing_mask.sum()\n",
        "\n",
        "#     if missing_count == 0:\n",
        "#         print(\"No missing labels found.\")\n",
        "#         return df_copy\n",
        "\n",
        "#     print(f\"Auto-labeling {missing_count} missing samples...\")\n",
        "\n",
        "#     missing_indices = df_copy[missing_mask].index.tolist()\n",
        "\n",
        "#     for i in range(0, len(missing_indices), batch_size):\n",
        "#         batch_indices = missing_indices[i:i+batch_size]\n",
        "#         texts = df_copy.loc[batch_indices, 'text'].tolist()\n",
        "\n",
        "#         # Build prompts for the batch\n",
        "#         prompts = [\n",
        "#             f\"\"\"You are a hate speech classification expert.\n",
        "# Classify the following text into exactly one of these categories:\n",
        "\n",
        "# None, Religious Hate, Sexism, Political Hate, Profane, Abusive\n",
        "\n",
        "# Text: \"{t}\"\n",
        "\n",
        "# Important: Respond with ONLY one category name from the list above.\"\"\"\n",
        "#             for t in texts\n",
        "#         ]\n",
        "\n",
        "#         try:\n",
        "#             outputs = qwen_pipeline(\n",
        "#                 prompts,\n",
        "#                 max_new_tokens=10,\n",
        "#                 do_sample=False,\n",
        "#                 batch_size=batch_size\n",
        "#             )\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
        "#             outputs = [[{\"generated_text\": \"\"}] for _ in prompts]\n",
        "\n",
        "#         # ✅ Handle nested list structure\n",
        "#         predicted_labels = []\n",
        "#         for out_group in outputs:\n",
        "#             if isinstance(out_group, list):\n",
        "#                 text_out = out_group[0][\"generated_text\"]\n",
        "#             else:\n",
        "#                 text_out = out_group[\"generated_text\"]\n",
        "\n",
        "#             found = next((label for label in l2id if label in text_out), \"None\")\n",
        "#             predicted_labels.append(found)\n",
        "\n",
        "#         # Assign predictions back to dataframe\n",
        "#         for idx, label in zip(batch_indices, predicted_labels):\n",
        "#             df_copy.loc[idx, 'label'] = label\n",
        "\n",
        "#         print(f\"✅ Processed batch {i//batch_size + 1}/{(len(missing_indices)-1)//batch_size + 1}\")\n",
        "\n",
        "#     print(\"🎉 Auto-labeling completed!\")\n",
        "#     return df_copy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZkTEO5mQe2Mx"
      },
      "outputs": [],
      "source": [
        "# # Cell 6: Load and Process Data\n",
        "# # =============================================================================\n",
        "# def load_and_process_data():\n",
        "#     \"\"\"Load and process all datasets\"\"\"\n",
        "\n",
        "#     # Load datasets\n",
        "#     print(\"Loading datasets...\")\n",
        "#     train_df = pd.read_csv('blp25_hatespeech_subtask_1A_train.tsv', sep='\\t')\n",
        "#     val_df = pd.read_csv('blp25_hatespeech_subtask_1A_dev.tsv', sep='\\t')\n",
        "#     test_df = pd.read_csv('blp25_hatespeech_subtask_1A_dev_test.tsv', sep='\\t')\n",
        "\n",
        "#     print(f\"Original dataset sizes:\")\n",
        "#     print(f\"Train: {len(train_df)} samples\")\n",
        "#     print(f\"Validation: {len(val_df)} samples\")\n",
        "#     print(f\"Test: {len(test_df)} samples\")\n",
        "\n",
        "#     # Check columns in each dataset\n",
        "#     print(f\"\\nDataset columns:\")\n",
        "#     print(f\"Train columns: {list(train_df.columns)}\")\n",
        "#     print(f\"Validation columns: {list(val_df.columns)}\")\n",
        "#     print(f\"Test columns: {list(test_df.columns)}\")\n",
        "\n",
        "#     # Add label column to test set if it doesn't exist\n",
        "#     if 'label' not in test_df.columns:\n",
        "#         print(\"Test dataset has no 'label' column. Adding empty label column.\")\n",
        "#         test_df['label'] = None\n",
        "\n",
        "#     # Check missing labels\n",
        "#     print(f\"\\nMissing labels:\")\n",
        "#     print(f\"Train: {train_df['label'].isna().sum()}\")\n",
        "#     print(f\"Validation: {val_df['label'].isna().sum()}\")\n",
        "#     print(f\"Test: {test_df['label'].isna().sum()}\")\n",
        "\n",
        "#     # Auto-label missing data\n",
        "#     train_df = auto_label_missing_data(train_df)\n",
        "#     val_df = auto_label_missing_data(val_df)\n",
        "#     test_df = auto_label_missing_data(test_df)\n",
        "\n",
        "#     # Verify no missing labels remain\n",
        "#     print(f\"\\nAfter auto-labeling - Missing labels:\")\n",
        "#     print(f\"Train: {train_df['label'].isna().sum()}\")\n",
        "#     print(f\"Validation: {val_df['label'].isna().sum()}\")\n",
        "#     print(f\"Test: {test_df['label'].isna().sum()}\")\n",
        "\n",
        "#     return train_df, val_df, test_df\n",
        "\n",
        "# # Load the data\n",
        "# train_df, val_df, test_df = load_and_process_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4DpnZ9j0fPmK"
      },
      "outputs": [],
      "source": [
        "# # Cell 7: Exploratory Data Analysis\n",
        "# # =============================================================================\n",
        "# def analyze_data(train_df, val_df, test_df):\n",
        "#     \"\"\"Perform exploratory data analysis\"\"\"\n",
        "\n",
        "#     print(\"=== TRAINING DATA ANALYSIS ===\")\n",
        "#     print(f\"Shape: {train_df.shape}\")\n",
        "#     print(f\"\\nLabel distribution:\")\n",
        "#     label_counts = train_df['label'].value_counts()\n",
        "#     label_percentages = train_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "#     for label in label_counts.index:\n",
        "#         print(f\"{label}: {label_counts[label]} ({label_percentages[label]:.2f}%)\")\n",
        "\n",
        "#     print(f\"\\nText statistics:\")\n",
        "#     train_df['text_length'] = train_df['text'].str.len()\n",
        "#     print(f\"Mean text length: {train_df['text_length'].mean():.2f}\")\n",
        "#     print(f\"Max text length: {train_df['text_length'].max()}\")\n",
        "#     print(f\"Min text length: {train_df['text_length'].min()}\")\n",
        "\n",
        "#     print(f\"\\nValidation set label distribution:\")\n",
        "#     print(val_df['label'].value_counts())\n",
        "\n",
        "#     return label_counts\n",
        "\n",
        "# label_counts = analyze_data(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vdRj7Vamf-6M"
      },
      "outputs": [],
      "source": [
        "# # Cell 8: Convert Labels to Numeric IDs\n",
        "# # =============================================================================\n",
        "# def convert_labels_to_ids(df):\n",
        "#     \"\"\"Convert string labels to numeric IDs\"\"\"\n",
        "#     df_copy = df.copy()\n",
        "#     df_copy['labels'] = df_copy['label'].map(l2id)\n",
        "\n",
        "#     # Check for any unmapped labels\n",
        "#     unmapped = df_copy['labels'].isna().sum()\n",
        "#     if unmapped > 0:\n",
        "#         print(f\"Warning: {unmapped} labels could not be mapped\")\n",
        "#         print(\"Unmapped labels:\", df_copy[df_copy['labels'].isna()]['label'].unique())\n",
        "#         # Fill unmapped with 0 (None)\n",
        "#         df_copy['labels'] = df_copy['labels'].fillna(0)\n",
        "\n",
        "#     return df_copy\n",
        "\n",
        "# import pandas as pd\n",
        "# # Convert labels for all datasets\n",
        "# train_df = convert_labels_to_ids(train_df)\n",
        "# val_df = convert_labels_to_ids(val_df)\n",
        "# test_df = convert_labels_to_ids(test_df)\n",
        "\n",
        "\n",
        "# print(\"Label conversion completed!\")\n",
        "# print(f\"Training set label distribution (numeric):\")\n",
        "# print(train_df['labels'].value_counts().sort_index())\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Example: save converted CSVs to a folder in your Drive\n",
        "# train_df.to_csv('/content/drive/MyDrive/ColabFiles/train_converted.csv', index=False)\n",
        "# val_df.to_csv('/content/drive/MyDrive/ColabFiles/val_converted.csv', index=False)\n",
        "# test_df.to_csv('/content/drive/MyDrive/ColabFiles/test_converted.csv', index=False)\n",
        "\n",
        "\n",
        "# print(\"Files saved to /content folder:\")\n",
        "# print(\" - train_converted.csv\")\n",
        "# print(\" - val_converted.csv\")\n",
        "# print(\" - test_converted.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "fb23c31206fa42788f32ec70d656ceb3",
            "1298a90f3e0f4b00a1208228efee3979",
            "e0d6387a86564962aabd5613c2161993",
            "bcef5927d561495583b6af16ed12acbc",
            "e8f836262d004f20aa4180815ceb933f",
            "4d692eccb542460984f8321bac9573b2",
            "a14a03fdaa2b425a814a9ee48e1afe64",
            "84c740128ae04dc0989a44bfca8c6754",
            "eb86010a8e7f4782b282a2a1ff9a2bed",
            "7caa9e32742b4cd1b16460d4e9f06d90",
            "95199f8ffb9045d59f0937a6e135a212",
            "e1ee08e30036461cbc0dd040dfb27de0",
            "ca97c1cda87a4437b634cde4e121750b",
            "6654c78a6d494f178583b43623128051",
            "add853328e914472873a36600b81986d",
            "9bd3a53834654a279b76f55bfa02ee83",
            "beb248bf8c3d4902999fdb89a3811a0d",
            "79b9a78501ed4650a33a700003f19a98",
            "6d723da869de4d76aa693d51c7756b75",
            "7a61f96012824e8c80ee690e513ab64e",
            "a7fb8f2cab7243f0a674c8da6ba9b155",
            "f9b95dde39e04edfb1836a4b72d3f49e",
            "843b5771a7d0424aba70a82af85582a0",
            "cd1e50141ddc429f95eb1cb1806c41fd",
            "6a6d4fc48f3c4b2798069a85e767988c",
            "63fc87deea5c4d998ba77eb0eb0401c9",
            "076261586ced450397179f6bf1aadfb4",
            "0da9e57d01004097ac5b31fd6cb332ec",
            "91dbbccf74f346f1a84b54825cde3d03",
            "4c3f8ed9e18e4b6fb9f3e50b369b00f1",
            "f1827cb8b1604c1ea0693cbe3008b52f",
            "4c888f4439af456c91f0e859110b4bd2",
            "eca22c006c6a42c697476076d28a388d"
          ]
        },
        "id": "FpqROfNFf_f_",
        "outputId": "a00b8eee-ff74-4db3-d2e9-63876d520073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer...\n",
            "Mounted at /content/drive\n",
            "Converting to HuggingFace datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/35522 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb23c31206fa42788f32ec70d656ceb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1ee08e30036461cbc0dd040dfb27de0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "843b5771a7d0424aba70a82af85582a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes after tokenization:\n",
            "Train: 35522\n",
            "Validation: 2512\n",
            "Test: 2512\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Setup Tokenization\n",
        "# =============================================================================\n",
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Ensure pad token is defined\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"left\"  # recommended for decoder-only models\n",
        "\n",
        "# Updated tokenize function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize text data with padding for batching\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # pad to MAX_LENGTH\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=None\n",
        "    )\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your saved CSVs from Drive\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ColabFiles/train_converted.csv')\n",
        "val_df   = pd.read_csv('/content/drive/MyDrive/ColabFiles/val_converted.csv')\n",
        "test_df  = pd.read_csv('/content/drive/MyDrive/ColabFiles/test_converted.csv')\n",
        "\n",
        "# Convert to HuggingFace datasets\n",
        "print(\"Converting to HuggingFace datasets...\")\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df[['text', 'labels']])\n",
        "val_dataset   = Dataset.from_pandas(val_df[['text', 'labels']])\n",
        "test_dataset  = Dataset.from_pandas(test_df[['text', 'labels']])\n",
        "\n",
        "# Apply tokenization\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset   = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset  = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for Trainer\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Dataset sizes after tokenization:\")\n",
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Validation: {len(val_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Exploratory Data Analysis\n",
        "# =============================================================================\n",
        "def analyze_data(train_df, val_df, test_df):\n",
        "    \"\"\"Perform exploratory data analysis\"\"\"\n",
        "\n",
        "    print(\"=== TRAINING DATA ANALYSIS ===\")\n",
        "    print(f\"Shape: {train_df.shape}\")\n",
        "    print(f\"\\nLabel distribution:\")\n",
        "    label_counts = train_df['label'].value_counts()\n",
        "    label_percentages = train_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "    for label in label_counts.index:\n",
        "        print(f\"{label}: {label_counts[label]} ({label_percentages[label]:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nText statistics:\")\n",
        "    train_df['text_length'] = train_df['text'].str.len()\n",
        "    print(f\"Mean text length: {train_df['text_length'].mean():.2f}\")\n",
        "    print(f\"Max text length: {train_df['text_length'].max()}\")\n",
        "    print(f\"Min text length: {train_df['text_length'].min()}\")\n",
        "\n",
        "    print(f\"\\nValidation set label distribution:\")\n",
        "    print(val_df['label'].value_counts())\n",
        "\n",
        "    #     # Check missing labels\n",
        "    print(f\"\\nMissing labels:\")\n",
        "    print(f\"Train: {train_df['label'].isna().sum()}\")\n",
        "    print(f\"Validation: {val_df['label'].isna().sum()}\")\n",
        "    print(f\"Test: {test_df['label'].isna().sum()}\")\n",
        "\n",
        "\n",
        "    return label_counts\n",
        "\n",
        "label_counts = analyze_data(train_df, val_df, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdnNAzF5fkib",
        "outputId": "8136dbf3-5cef-4626-d854-e1597aa0b97e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TRAINING DATA ANALYSIS ===\n",
            "Shape: (35522, 5)\n",
            "\n",
            "Label distribution:\n",
            "Abusive: 8212 (52.75%)\n",
            "Political Hate: 4227 (27.15%)\n",
            "Profane: 2331 (14.97%)\n",
            "Religious Hate: 676 (4.34%)\n",
            "Sexism: 122 (0.78%)\n",
            "\n",
            "Text statistics:\n",
            "Mean text length: 78.21\n",
            "Max text length: 3710\n",
            "Min text length: 7\n",
            "\n",
            "Validation set label distribution:\n",
            "label\n",
            "Abusive           564\n",
            "Political Hate    291\n",
            "Profane           157\n",
            "Religious Hate     38\n",
            "Sexism             11\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUYewGz9gC-e",
        "outputId": "66154fb5-7d7f-4b84-a838-cbe0623892cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "  None (ID: 0): 0.297\n",
            "  Religious Hate (ID: 1): 8.758\n",
            "  Sexism (ID: 2): 48.527\n",
            "  Political Hate (ID: 3): 1.401\n",
            "  Profane (ID: 4): 2.540\n",
            "  Abusive (ID: 5): 0.721\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Compute Class Weights for Balanced Training\n",
        "# =============================================================================\n",
        "def compute_class_weights(labels):\n",
        "    \"\"\"Compute class weights for balanced training\"\"\"\n",
        "    unique_labels = np.unique(labels)\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=unique_labels,\n",
        "        y=labels\n",
        "    )\n",
        "\n",
        "    # Create weight dict\n",
        "    weight_dict = {int(label): weight for label, weight in zip(unique_labels, class_weights)}\n",
        "\n",
        "    print(\"Class weights:\")\n",
        "    for label_id, weight in weight_dict.items():\n",
        "        label_name = id2l[label_id]\n",
        "        print(f\"  {label_name} (ID: {label_id}): {weight:.3f}\")\n",
        "\n",
        "    return torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weights(train_df['labels'].values)\n",
        "\n",
        "# Cell 11: Custom Trainer with Weighted Loss\n",
        "# =============================================================================\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer with weighted CrossEntropyLoss\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        \"\"\"Compute weighted loss\"\"\"\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Move class weights to same device as logits\n",
        "        if self.class_weights is not None:\n",
        "            weights = self.class_weights.to(logits.device)\n",
        "            loss_fct = CrossEntropyLoss(weight=weights)\n",
        "        else:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljH0DqgDgIwd",
        "outputId": "58a11447-19bb-4356-8a5a-61ad51ce2e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "  None (ID: 0): 0.297\n",
            "  Religious Hate (ID: 1): 8.758\n",
            "  Sexism (ID: 2): 48.527\n",
            "  Political Hate (ID: 3): 1.401\n",
            "  Profane (ID: 4): 2.540\n",
            "  Abusive (ID: 5): 0.721\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Compute Class Weights for Balanced Training\n",
        "# =============================================================================\n",
        "def compute_class_weights(labels):\n",
        "    \"\"\"Compute class weights for balanced training\"\"\"\n",
        "    unique_labels = np.unique(labels)\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=unique_labels,\n",
        "        y=labels\n",
        "    )\n",
        "\n",
        "    # Create weight dict\n",
        "    weight_dict = {int(label): weight for label, weight in zip(unique_labels, class_weights)}\n",
        "\n",
        "    print(\"Class weights:\")\n",
        "    for label_id, weight in weight_dict.items():\n",
        "        label_name = id2l[label_id]\n",
        "        print(f\"  {label_name} (ID: {label_id}): {weight:.3f}\")\n",
        "\n",
        "    return torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weights(train_df['labels'].values)\n",
        "\n",
        "# Cell 11: Custom Trainer with Weighted Loss\n",
        "# =============================================================================\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer with weighted CrossEntropyLoss\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"Compute weighted loss\"\"\"\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Move class weights to same device as logits\n",
        "        if self.class_weights is not None:\n",
        "            weights = self.class_weights.to(logits.device)\n",
        "            loss_fct = CrossEntropyLoss(weight=weights)\n",
        "        else:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g6Dnqd2Wgyrp"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Define Evaluation Metrics\n",
        "# =============================================================================\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Per-class metrics\n",
        "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1,\n",
        "        'precision_macro': precision,\n",
        "        'recall_macro': recall,\n",
        "    }\n",
        "\n",
        "    # Add per-class metrics\n",
        "    for i, label_name in id2l.items():\n",
        "        if i < len(f1_per_class):\n",
        "            metrics[f'f1_{label_name.replace(\" \", \"_\")}'] = f1_per_class[i]\n",
        "            metrics[f'precision_{label_name.replace(\" \", \"_\")}'] = precision_per_class[i]\n",
        "            metrics[f'recall_{label_name.replace(\" \", \"_\")}'] = recall_per_class[i]\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "b0e6bd6c579940178aed62bcb8f56f7a",
            "de37477cfe7b44be9ae9e4cf407abfb1",
            "452033d5a6b34be88ac1ad6778669b9f",
            "b3fa26344d3e4705a71199a07a92c24c",
            "cc246759c5a747edae1e79c636723643",
            "6dfb8234c9004ff4aa7656937c185df0",
            "317f27dbd0714d0db58e5ff0ebf05b1a",
            "9c19c6f0e67e488fadf431acadec086f",
            "a4523c7794e542e6b36cdefc239d6910",
            "04949eb231994e20a7a827ebb03f1578",
            "e94938d104d54edd97d9a4fc549dd5aa"
          ]
        },
        "id": "oq09NuJLgPFM",
        "outputId": "cca1e8fc-4235-4048-d127-de8a1a0c901c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0e6bd6c579940178aed62bcb8f56f7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 6 classes\n",
            "Optimized training arguments configured with early stopping\n",
            "Learning rate: 1e-05\n",
            "Batch size: 8\n",
            "Max epochs: 8\n",
            "Early stopping patience: 2 epochs\n"
          ]
        }
      ],
      "source": [
        "# Cell 13: Load Model and Setup Optimized Training Configuration\n",
        "# =============================================================================\n",
        "print(\"Loading model...\")\n",
        "config = AutoConfig.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(l2id),\n",
        "    id2label=id2l,\n",
        "    label2id=l2id,\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=6,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float32  # use FP32 instead\n",
        ")\n",
        "\n",
        "# Tell the model what pad token ID to use\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(f\"Model loaded with {len(l2id)} classes\")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# 🎯 OPTIMIZED TRAINING ARGUMENTS BASED ON YOUR SUCCESSFUL CONFIGURATION\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./xlm_roberta_recovery/\",\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "    # 🔧 ADJUSTED LEARNING SCHEDULE - Lower LR for stable convergence\n",
        "    learning_rate=LEARNING_RATE,           # 10e-6 for stability\n",
        "    num_train_epochs=4,           # 8 epochs with early stopping\n",
        "    warmup_ratio=WARMUP_RATIO,             # 0.15 for longer warmup\n",
        "    lr_scheduler_type=\"cosine\",            # Smoother LR decay\n",
        "\n",
        "    # 🛡️ STRONGER REGULARIZATION - Combat overfitting\n",
        "    weight_decay=WEIGHT_DECAY,             # 0.01 regularization\n",
        "    max_grad_norm=MAX_GRAD_NORM,           # 0.5 gradient clipping\n",
        "    dataloader_drop_last=True,             # Consistent batch sizes\n",
        "\n",
        "    # ✅ OPTIMIZED BATCH CONFIGURATION\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=1,\n",
        "\n",
        "    # 🎯 EARLY STOPPING CONFIGURATION\n",
        "    eval_strategy=\"epoch\",           # Eval every epoch\n",
        "    save_strategy=\"epoch\",                 # Save every epoch\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1_macro\", # Use macro F1 as primary metric\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # 📊 COMPREHENSIVE MONITORING\n",
        "    logging_steps=250,                     # More frequent logging\n",
        "    save_total_limit=3,                    # Keep only best 3 checkpoints\n",
        "\n",
        "    # 🔧 SYSTEM OPTIMIZATIONS\n",
        "    report_to=None,                        # Disable wandb\n",
        "    dataloader_num_workers=2,\n",
        "    fp16=False,                            # Mixed precision for efficiency\n",
        "    group_by_length=True,                 # Batch similar lengths together\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# 🛑 MANDATORY EARLY STOPPING - Prevent overfitting\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=2,            # Stop after 2 epochs without improvement\n",
        "    early_stopping_threshold=0.001        # Minimum improvement threshold\n",
        ")\n",
        "\n",
        "print(\"Optimized training arguments configured with early stopping\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Max epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Early stopping patience: 2 epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PifZouKFHiAn",
        "outputId": "3052911d-2a48-4f0a-ab88-3879e61440fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Clear PyTorch GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Run garbage collection\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "M86tSVOHgSu6",
        "outputId": "021de48b-366d-4ffa-b9ea-f2fbc8ffad9f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Training on 35522 samples\n",
            "Validating on 2512 samples\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrakib911hossan\u001b[0m (\u001b[33mrakib911hossan-bangladesh-university-of-business-and-tec\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250901_042315-pnsyyi88</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface/runs/pnsyyi88' target=\"_blank\">vague-cherry-8</a></strong> to <a href='https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface' target=\"_blank\">https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface/runs/pnsyyi88' target=\"_blank\">https://wandb.ai/rakib911hossan-bangladesh-university-of-business-and-tec/huggingface/runs/pnsyyi88</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16545' max='17760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16545/17760 3:43:06 < 16:23, 1.24 it/s, Epoch 3.73/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 None</th>\n",
              "      <th>Precision None</th>\n",
              "      <th>Recall None</th>\n",
              "      <th>F1 Religious Hate</th>\n",
              "      <th>Precision Religious Hate</th>\n",
              "      <th>Recall Religious Hate</th>\n",
              "      <th>F1 Sexism</th>\n",
              "      <th>Precision Sexism</th>\n",
              "      <th>Recall Sexism</th>\n",
              "      <th>F1 Political Hate</th>\n",
              "      <th>Precision Political Hate</th>\n",
              "      <th>Recall Political Hate</th>\n",
              "      <th>F1 Profane</th>\n",
              "      <th>Precision Profane</th>\n",
              "      <th>Recall Profane</th>\n",
              "      <th>F1 Abusive</th>\n",
              "      <th>Precision Abusive</th>\n",
              "      <th>Recall Abusive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.092900</td>\n",
              "      <td>0.966528</td>\n",
              "      <td>0.666003</td>\n",
              "      <td>0.528364</td>\n",
              "      <td>0.522995</td>\n",
              "      <td>0.571981</td>\n",
              "      <td>0.771917</td>\n",
              "      <td>0.837228</td>\n",
              "      <td>0.716058</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.568365</td>\n",
              "      <td>0.465934</td>\n",
              "      <td>0.728522</td>\n",
              "      <td>0.702550</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.789809</td>\n",
              "      <td>0.496403</td>\n",
              "      <td>0.503650</td>\n",
              "      <td>0.489362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.967100</td>\n",
              "      <td>0.914041</td>\n",
              "      <td>0.666003</td>\n",
              "      <td>0.548824</td>\n",
              "      <td>0.501977</td>\n",
              "      <td>0.638509</td>\n",
              "      <td>0.760093</td>\n",
              "      <td>0.870222</td>\n",
              "      <td>0.674707</td>\n",
              "      <td>0.448598</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.565986</td>\n",
              "      <td>0.468468</td>\n",
              "      <td>0.714777</td>\n",
              "      <td>0.734043</td>\n",
              "      <td>0.630137</td>\n",
              "      <td>0.878981</td>\n",
              "      <td>0.534224</td>\n",
              "      <td>0.504732</td>\n",
              "      <td>0.567376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.837300</td>\n",
              "      <td>0.911352</td>\n",
              "      <td>0.679538</td>\n",
              "      <td>0.561765</td>\n",
              "      <td>0.527738</td>\n",
              "      <td>0.625071</td>\n",
              "      <td>0.775146</td>\n",
              "      <td>0.887900</td>\n",
              "      <td>0.687802</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.563969</td>\n",
              "      <td>0.454737</td>\n",
              "      <td>0.742268</td>\n",
              "      <td>0.749326</td>\n",
              "      <td>0.649533</td>\n",
              "      <td>0.885350</td>\n",
              "      <td>0.551089</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17760' max='17760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17760/17760 4:00:57, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 None</th>\n",
              "      <th>Precision None</th>\n",
              "      <th>Recall None</th>\n",
              "      <th>F1 Religious Hate</th>\n",
              "      <th>Precision Religious Hate</th>\n",
              "      <th>Recall Religious Hate</th>\n",
              "      <th>F1 Sexism</th>\n",
              "      <th>Precision Sexism</th>\n",
              "      <th>Recall Sexism</th>\n",
              "      <th>F1 Political Hate</th>\n",
              "      <th>Precision Political Hate</th>\n",
              "      <th>Recall Political Hate</th>\n",
              "      <th>F1 Profane</th>\n",
              "      <th>Precision Profane</th>\n",
              "      <th>Recall Profane</th>\n",
              "      <th>F1 Abusive</th>\n",
              "      <th>Precision Abusive</th>\n",
              "      <th>Recall Abusive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.092900</td>\n",
              "      <td>0.966528</td>\n",
              "      <td>0.666003</td>\n",
              "      <td>0.528364</td>\n",
              "      <td>0.522995</td>\n",
              "      <td>0.571981</td>\n",
              "      <td>0.771917</td>\n",
              "      <td>0.837228</td>\n",
              "      <td>0.716058</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.568365</td>\n",
              "      <td>0.465934</td>\n",
              "      <td>0.728522</td>\n",
              "      <td>0.702550</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.789809</td>\n",
              "      <td>0.496403</td>\n",
              "      <td>0.503650</td>\n",
              "      <td>0.489362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.967100</td>\n",
              "      <td>0.914041</td>\n",
              "      <td>0.666003</td>\n",
              "      <td>0.548824</td>\n",
              "      <td>0.501977</td>\n",
              "      <td>0.638509</td>\n",
              "      <td>0.760093</td>\n",
              "      <td>0.870222</td>\n",
              "      <td>0.674707</td>\n",
              "      <td>0.448598</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.565986</td>\n",
              "      <td>0.468468</td>\n",
              "      <td>0.714777</td>\n",
              "      <td>0.734043</td>\n",
              "      <td>0.630137</td>\n",
              "      <td>0.878981</td>\n",
              "      <td>0.534224</td>\n",
              "      <td>0.504732</td>\n",
              "      <td>0.567376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.837300</td>\n",
              "      <td>0.911352</td>\n",
              "      <td>0.679538</td>\n",
              "      <td>0.561765</td>\n",
              "      <td>0.527738</td>\n",
              "      <td>0.625071</td>\n",
              "      <td>0.775146</td>\n",
              "      <td>0.887900</td>\n",
              "      <td>0.687802</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.563969</td>\n",
              "      <td>0.454737</td>\n",
              "      <td>0.742268</td>\n",
              "      <td>0.749326</td>\n",
              "      <td>0.649533</td>\n",
              "      <td>0.885350</td>\n",
              "      <td>0.551089</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.769600</td>\n",
              "      <td>0.931508</td>\n",
              "      <td>0.692675</td>\n",
              "      <td>0.573149</td>\n",
              "      <td>0.536574</td>\n",
              "      <td>0.631880</td>\n",
              "      <td>0.786960</td>\n",
              "      <td>0.874473</td>\n",
              "      <td>0.715369</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.568600</td>\n",
              "      <td>0.483173</td>\n",
              "      <td>0.690722</td>\n",
              "      <td>0.772334</td>\n",
              "      <td>0.705263</td>\n",
              "      <td>0.853503</td>\n",
              "      <td>0.560794</td>\n",
              "      <td>0.525581</td>\n",
              "      <td>0.601064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Cell 14: Initialize Trainer and Start Training\n",
        "# =============================================================================\n",
        "# Initialize trainer with weighted loss\n",
        "trainer = WeightedTrainer(\n",
        "    class_weights=class_weights,\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training on {len(train_dataset)} samples\")\n",
        "print(f\"Validating on {len(val_dataset)} samples\")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AzyaFicqgh9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3f82a3a7-2b70-4ffd-be15-052d762a277f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FINAL TEST RESULTS ===\n",
            "Accuracy: 0.4817\n",
            "Macro F1: 0.1084\n",
            "Macro Precision: 0.1667\n",
            "Macro Recall: 0.0803\n"
          ]
        }
      ],
      "source": [
        "# Cell 15: Evaluation on Test Set\n",
        "# =============================================================================\n",
        "print(\"Evaluating on test set...\")\n",
        "\n",
        "# Make predictions on test set\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "test_labels = test_predictions.label_ids\n",
        "\n",
        "# Compute final metrics\n",
        "final_metrics = compute_metrics((test_predictions.predictions, test_labels))\n",
        "\n",
        "print(\"=== FINAL TEST RESULTS ===\")\n",
        "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {final_metrics['f1_macro']:.4f}\")\n",
        "print(f\"Macro Precision: {final_metrics['precision_macro']:.4f}\")\n",
        "print(f\"Macro Recall: {final_metrics['recall_macro']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_O1NmBFohDFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57faf76-23f8-4975-bbc7-607151a29410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DETAILED CLASSIFICATION REPORT ===\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          None     1.0000    0.4817    0.6502      2512\n",
            "Religious Hate     0.0000    0.0000    0.0000         0\n",
            "        Sexism     0.0000    0.0000    0.0000         0\n",
            "Political Hate     0.0000    0.0000    0.0000         0\n",
            "       Profane     0.0000    0.0000    0.0000         0\n",
            "       Abusive     0.0000    0.0000    0.0000         0\n",
            "\n",
            "      accuracy                         0.4817      2512\n",
            "     macro avg     0.1667    0.0803    0.1084      2512\n",
            "  weighted avg     1.0000    0.4817    0.6502      2512\n",
            "\n",
            "\n",
            "=== PER-CLASS RESULTS ===\n",
            "None:\n",
            "  Precision: 1.0000\n",
            "  Recall: 0.4817\n",
            "  F1-Score: 0.6502\n",
            "  Support: 2512\n",
            "\n",
            "Religious Hate:\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-Score: 0.0000\n",
            "  Support: 0\n",
            "\n",
            "Sexism:\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-Score: 0.0000\n",
            "  Support: 0\n",
            "\n",
            "Political Hate:\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-Score: 0.0000\n",
            "  Support: 0\n",
            "\n",
            "Profane:\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-Score: 0.0000\n",
            "  Support: 0\n",
            "\n",
            "Abusive:\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-Score: 0.0000\n",
            "  Support: 0\n",
            "\n",
            "\n",
            "Missing labels:\n",
            "Train: 0\n",
            "Validation: 0\n",
            "Test: 0\n"
          ]
        }
      ],
      "source": [
        "# Cell 16: Detailed Classification Report\n",
        "# =============================================================================\n",
        "print(\"\\n=== DETAILED CLASSIFICATION REPORT ===\")\n",
        "\n",
        "# Generate classification report\n",
        "target_names = [id2l[i] for i in range(len(l2id))]\n",
        "report = classification_report(\n",
        "    test_labels,\n",
        "    test_preds,\n",
        "    target_names=target_names,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(report)\n",
        "\n",
        "# Print per-class results\n",
        "print(\"\\n=== PER-CLASS RESULTS ===\")\n",
        "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
        "    test_labels, test_preds, average=None, zero_division=0\n",
        ")\n",
        "\n",
        "for i, label_name in enumerate(target_names):\n",
        "    if i < len(f1_per_class):\n",
        "        print(f\"{label_name}:\")\n",
        "        print(f\"  Precision: {precision_per_class[i]:.4f}\")\n",
        "        print(f\"  Recall: {recall_per_class[i]:.4f}\")\n",
        "        print(f\"  F1-Score: {f1_per_class[i]:.4f}\")\n",
        "        print(f\"  Support: {support_per_class[i]}\")\n",
        "        print()\n",
        "\n",
        " #     # Check missing labels\n",
        "print(f\"\\nMissing labels:\")\n",
        "print(f\"Train: {train_df['labels'].isna().sum()}\")\n",
        "print(f\"Validation: {val_df['labels'].isna().sum()}\")\n",
        "print(f\"Test: {test_df['labels'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " git config --global user.email \"rakib911hossan@gmail.com\"\n",
        "  git config --global user.name \"Rakib911Hossan\"\n",
        "\n",
        "!git clone https://github.com/Rakib911Hossan/hate_speech_detection.git\n",
        "%cd hate_speech_detection\n",
        "# move your notebook here\n",
        "!git add subtask_1a_xlm_roberta_qwen_label2.ipynb\n",
        "!git commit -m \"Update notebook\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "fMWmctrNZarL",
        "outputId": "ca4c0e34-810d-4b40-defa-42744ee39369"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2228826456.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2228826456.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git config --global user.email \"rakib911hossan@gmail.com\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlKpfHOIiypi"
      },
      "outputs": [],
      "source": [
        "# Cell 17: Save Optimized Model and Results\n",
        "# =============================================================================\n",
        "print(\"💾 Saving optimized model and tokenizer...\")\n",
        "\n",
        "# Save the fine-tuned model with optimized configuration\n",
        "model.save_pretrained(\"./xlm-roberta-hate-speech-optimized\")\n",
        "tokenizer.save_pretrained(\"./xlm-roberta-hate-speech-optimized\")\n",
        "\n",
        "# Save detailed results\n",
        "results_df = pd.DataFrame({\n",
        "    'id': test_df['id'].values,\n",
        "    'text': test_df['text'].values,\n",
        "    'true_label': [id2l[label] for label in test_labels],\n",
        "    'predicted_label': [id2l[pred] for pred in test_preds],\n",
        "    'correct': test_labels == test_preds\n",
        "})\n",
        "\n",
        "results_df.to_csv('optimized_test_results.csv', index=False)\n",
        "\n",
        "# Save training configuration for reference\n",
        "config_info = {\n",
        "    'model_name': MODEL_NAME,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'max_epochs': NUM_EPOCHS,\n",
        "    'warmup_ratio': WARMUP_RATIO,\n",
        "    'weight_decay': WEIGHT_DECAY,\n",
        "    'max_grad_norm': MAX_GRAD_NORM,\n",
        "    'early_stopping_patience': 2,\n",
        "    'scheduler': 'cosine',\n",
        "    'fp16': True,\n",
        "    'final_test_accuracy': (test_labels == test_preds).mean(),\n",
        "    'final_macro_f1': final_metrics['f1_macro']\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('training_config.json', 'w') as f:\n",
        "    json.dump(config_info, f, indent=2)\n",
        "\n",
        "print(\"✅ Model and results saved!\")\n",
        "print(f\"🎯 Test accuracy: {(test_labels == test_preds).mean():.4f}\")\n",
        "print(f\"📈 Macro F1: {final_metrics['f1_macro']:.4f}\")\n",
        "print(f\"📁 Model saved to: ./xlm-roberta-hate-speech-optimized\")\n",
        "print(f\"📊 Results saved to: optimized_test_results.csv\")\n",
        "print(f\"⚙️ Config saved to: training_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB0fdupUvbva"
      },
      "outputs": [],
      "source": [
        "# Cell 18: Example Predictions\n",
        "# =============================================================================\n",
        "def predict_text(text, model, tokenizer, device='cpu'):\n",
        "    \"\"\"Predict label for a single text\"\"\"\n",
        "    model.eval()\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=MAX_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_id = torch.argmax(predictions, dim=-1).item()\n",
        "        confidence = predictions[0][predicted_id].item()\n",
        "\n",
        "    return id2l[predicted_id], confidence\n",
        "\n",
        "# Test with some examples\n",
        "print(\"\\n=== EXAMPLE PREDICTIONS ===\")\n",
        "example_texts = [\n",
        "    \"This is a normal text with no hate speech\",\n",
        "    \"I hate all politicians they are corrupt\",\n",
        "    \"Religious people are stupid and should be eliminated\",\n",
        "    \"Women belong in the kitchen not in workplace\"\n",
        "]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for text in example_texts:\n",
        "    pred_label, confidence = predict_text(text, model, tokenizer, device)\n",
        "    print(f\"Text: {text[:50]}...\")\n",
        "    print(f\"Prediction: {pred_label} (confidence: {confidence:.3f})\")\n",
        "    print()\n",
        "\n",
        "print(\"=== TRAINING COMPLETE ===\")\n",
        "print(\"Your hate speech classifier is ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgLzUzxKvck9"
      },
      "outputs": [],
      "source": [
        "# Cell 19: Optimized Model Summary and Final Statistics\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 OPTIMIZED TRAINING COMPLETE - FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"🤖 Model: {MODEL_NAME}\")\n",
        "print(f\"📊 Training samples: {len(train_dataset)}\")\n",
        "print(f\"📊 Validation samples: {len(val_dataset)}\")\n",
        "print(f\"📊 Test samples: {len(test_dataset)}\")\n",
        "print(f\"🏷️  Number of classes: {len(l2id)}\")\n",
        "print(f\"📝 Max sequence length: {MAX_LENGTH}\")\n",
        "\n",
        "print(f\"\\n🔧 OPTIMIZED HYPERPARAMETERS:\")\n",
        "print(f\"  • Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  • Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  • Max epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  • Warmup ratio: {WARMUP_RATIO}\")\n",
        "print(f\"  • Weight decay: {WEIGHT_DECAY}\")\n",
        "print(f\"  • Gradient clipping: {MAX_GRAD_NORM}\")\n",
        "print(f\"  • Scheduler: cosine\")\n",
        "print(f\"  • Early stopping: patience=2\")\n",
        "print(f\"  • Mixed precision: FP16\")\n",
        "\n",
        "print(f\"\\n🎯 FINAL PERFORMANCE:\")\n",
        "print(f\"  • Test Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "print(f\"  • Macro F1-Score: {final_metrics['f1_macro']:.4f}\")\n",
        "print(f\"  • Macro Precision: {final_metrics['precision_macro']:.4f}\")\n",
        "print(f\"  • Macro Recall: {final_metrics['recall_macro']:.4f}\")\n",
        "\n",
        "print(f\"\\n📁 FILES GENERATED:\")\n",
        "print(f\"  • ./xlm-roberta-hate-speech-optimized/ (optimized model)\")\n",
        "print(f\"  • optimized_test_results.csv (detailed predictions)\")\n",
        "print(f\"  • training_config.json (hyperparameter configuration)\")\n",
        "\n",
        "print(f\"\\n🔄 TO LOAD THE OPTIMIZED MODEL LATER:\")\n",
        "print(\"```python\")\n",
        "print(\"from transformers import AutoModelForSequenceClassification, AutoTokenizer\")\n",
        "print(\"model = AutoModelForSequenceClassification.from_pretrained('./xlm-roberta-hate-speech-optimized')\")\n",
        "print(\"tokenizer = AutoTokenizer.from_pretrained('./xlm-roberta-hate-speech-optimized')\")\n",
        "print(\"```\")\n",
        "\n",
        "print(f\"\\n🚀 OPTIMIZATIONS APPLIED:\")\n",
        "print(\"  ✅ Lower learning rate for stable convergence\")\n",
        "print(\"  ✅ Early stopping to prevent overfitting\")\n",
        "print(\"  ✅ Cosine learning rate scheduling\")\n",
        "print(\"  ✅ Stronger regularization (weight decay)\")\n",
        "print(\"  ✅ Gradient clipping for stability\")\n",
        "print(\"  ✅ Mixed precision training\")\n",
        "print(\"  ✅ Weighted loss for class balance\")\n",
        "print(\"  ✅ Longer warmup period\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🎊 Your optimized hate speech classifier is ready!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb23c31206fa42788f32ec70d656ceb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1298a90f3e0f4b00a1208228efee3979",
              "IPY_MODEL_e0d6387a86564962aabd5613c2161993",
              "IPY_MODEL_bcef5927d561495583b6af16ed12acbc"
            ],
            "layout": "IPY_MODEL_e8f836262d004f20aa4180815ceb933f"
          }
        },
        "1298a90f3e0f4b00a1208228efee3979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d692eccb542460984f8321bac9573b2",
            "placeholder": "​",
            "style": "IPY_MODEL_a14a03fdaa2b425a814a9ee48e1afe64",
            "value": "Map: 100%"
          }
        },
        "e0d6387a86564962aabd5613c2161993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c740128ae04dc0989a44bfca8c6754",
            "max": 35522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb86010a8e7f4782b282a2a1ff9a2bed",
            "value": 35522
          }
        },
        "bcef5927d561495583b6af16ed12acbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7caa9e32742b4cd1b16460d4e9f06d90",
            "placeholder": "​",
            "style": "IPY_MODEL_95199f8ffb9045d59f0937a6e135a212",
            "value": " 35522/35522 [00:18&lt;00:00, 3236.67 examples/s]"
          }
        },
        "e8f836262d004f20aa4180815ceb933f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d692eccb542460984f8321bac9573b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14a03fdaa2b425a814a9ee48e1afe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c740128ae04dc0989a44bfca8c6754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb86010a8e7f4782b282a2a1ff9a2bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7caa9e32742b4cd1b16460d4e9f06d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95199f8ffb9045d59f0937a6e135a212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1ee08e30036461cbc0dd040dfb27de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca97c1cda87a4437b634cde4e121750b",
              "IPY_MODEL_6654c78a6d494f178583b43623128051",
              "IPY_MODEL_add853328e914472873a36600b81986d"
            ],
            "layout": "IPY_MODEL_9bd3a53834654a279b76f55bfa02ee83"
          }
        },
        "ca97c1cda87a4437b634cde4e121750b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb248bf8c3d4902999fdb89a3811a0d",
            "placeholder": "​",
            "style": "IPY_MODEL_79b9a78501ed4650a33a700003f19a98",
            "value": "Map: 100%"
          }
        },
        "6654c78a6d494f178583b43623128051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d723da869de4d76aa693d51c7756b75",
            "max": 2512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a61f96012824e8c80ee690e513ab64e",
            "value": 2512
          }
        },
        "add853328e914472873a36600b81986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fb8f2cab7243f0a674c8da6ba9b155",
            "placeholder": "​",
            "style": "IPY_MODEL_f9b95dde39e04edfb1836a4b72d3f49e",
            "value": " 2512/2512 [00:00&lt;00:00, 3218.04 examples/s]"
          }
        },
        "9bd3a53834654a279b76f55bfa02ee83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb248bf8c3d4902999fdb89a3811a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b9a78501ed4650a33a700003f19a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d723da869de4d76aa693d51c7756b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a61f96012824e8c80ee690e513ab64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7fb8f2cab7243f0a674c8da6ba9b155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b95dde39e04edfb1836a4b72d3f49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843b5771a7d0424aba70a82af85582a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd1e50141ddc429f95eb1cb1806c41fd",
              "IPY_MODEL_6a6d4fc48f3c4b2798069a85e767988c",
              "IPY_MODEL_63fc87deea5c4d998ba77eb0eb0401c9"
            ],
            "layout": "IPY_MODEL_076261586ced450397179f6bf1aadfb4"
          }
        },
        "cd1e50141ddc429f95eb1cb1806c41fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0da9e57d01004097ac5b31fd6cb332ec",
            "placeholder": "​",
            "style": "IPY_MODEL_91dbbccf74f346f1a84b54825cde3d03",
            "value": "Map: 100%"
          }
        },
        "6a6d4fc48f3c4b2798069a85e767988c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3f8ed9e18e4b6fb9f3e50b369b00f1",
            "max": 2512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1827cb8b1604c1ea0693cbe3008b52f",
            "value": 2512
          }
        },
        "63fc87deea5c4d998ba77eb0eb0401c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c888f4439af456c91f0e859110b4bd2",
            "placeholder": "​",
            "style": "IPY_MODEL_eca22c006c6a42c697476076d28a388d",
            "value": " 2512/2512 [00:00&lt;00:00, 3282.92 examples/s]"
          }
        },
        "076261586ced450397179f6bf1aadfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da9e57d01004097ac5b31fd6cb332ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91dbbccf74f346f1a84b54825cde3d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3f8ed9e18e4b6fb9f3e50b369b00f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1827cb8b1604c1ea0693cbe3008b52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c888f4439af456c91f0e859110b4bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca22c006c6a42c697476076d28a388d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0e6bd6c579940178aed62bcb8f56f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de37477cfe7b44be9ae9e4cf407abfb1",
              "IPY_MODEL_452033d5a6b34be88ac1ad6778669b9f",
              "IPY_MODEL_b3fa26344d3e4705a71199a07a92c24c"
            ],
            "layout": "IPY_MODEL_cc246759c5a747edae1e79c636723643"
          }
        },
        "de37477cfe7b44be9ae9e4cf407abfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dfb8234c9004ff4aa7656937c185df0",
            "placeholder": "​",
            "style": "IPY_MODEL_317f27dbd0714d0db58e5ff0ebf05b1a",
            "value": "model.safetensors: 100%"
          }
        },
        "452033d5a6b34be88ac1ad6778669b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c19c6f0e67e488fadf431acadec086f",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4523c7794e542e6b36cdefc239d6910",
            "value": 1115567652
          }
        },
        "b3fa26344d3e4705a71199a07a92c24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04949eb231994e20a7a827ebb03f1578",
            "placeholder": "​",
            "style": "IPY_MODEL_e94938d104d54edd97d9a4fc549dd5aa",
            "value": " 1.12G/1.12G [00:27&lt;00:00, 36.6MB/s]"
          }
        },
        "cc246759c5a747edae1e79c636723643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfb8234c9004ff4aa7656937c185df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317f27dbd0714d0db58e5ff0ebf05b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c19c6f0e67e488fadf431acadec086f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4523c7794e542e6b36cdefc239d6910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04949eb231994e20a7a827ebb03f1578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e94938d104d54edd97d9a4fc549dd5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}